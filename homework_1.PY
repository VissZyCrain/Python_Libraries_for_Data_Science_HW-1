# -*- coding: utf-8 -*-
"""GB_seminar_23-05-2024

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16hUQ9WNTbiICpzz9c69yab-HhVvl5zYX

## Курс "Библиотеки Python для Data Science: Numpy, Matplotlib, Scikit-learn"
## Практическое задание к семинару № 2 от 23-05-2024

## Тема “Вычисления с помощью Numpy”

### Задание 1
Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк
и 2 столбцов. Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6,
8, 11, 10, 7. Будем считать, что каждый столбец - это признак, а строка - наблюдение.
Затем найдите среднее значение по каждому признаку, используя метод mean массива
Numpy. Результат запишите в массив mean_a, в нем должно быть 2 элемента.
"""

import numpy as np

# Создаем массив a размером 5x2
a = np.array([[1, 6],
              [2, 8],
              [3, 11],
              [3, 10],
              [1, 7]])

# Находим среднее значение по каждому признаку (столбцу)
mean_a = np.mean(a, axis=0)

# Выводим массив mean_a
print(mean_a)

"""### Задание 2
Вычислите массив a_centered, отняв от значений массива “а” средние значения
соответствующих признаков, содержащиеся в массиве mean_a. Вычисление должно
производиться в одно действие. Получившийся массив должен иметь размер 5x2.
"""

# Вычитаем средние значения из массива a, чтобы получить массив a_centered
a_centered = a - mean_a

# Выводим массив a_centered
print(a_centered)

"""### Задание 3
Найдите скалярное произведение столбцов массива a_centered. В результате должна
получиться величина a_centered_sp. Затем поделите a_centered_sp на N-1, где N - число наблюдений.
"""

# Находим скалярное произведение столбцов массива a_centered
a_centered_sp = np.dot(a_centered[:, 0], a_centered[:, 1])

# Число наблюдений
N = a.shape[0]

# Делим a_centered_sp на N-1
result = a_centered_sp / (N - 1)

print("Скалярное произведение столбцов массива a_centered:", a_centered_sp)
print("Результат деления на N-1:", result)

"""### Задание 4**
Число, которое мы получили в конце задания 3 является ковариацией двух признаков, содержащихся
в массиве “а”. В задании 4 мы делили сумму произведений центрированных признаков на N-1, а не на
N, поэтому полученная нами величина является несмещенной оценкой ковариации.<p/>

В этом задании проверьте получившееся число, вычислив ковариацию еще одним способом - с
помощью функции np.cov. В качестве аргумента m функция np.cov должна принимать
транспонированный массив “a”. В получившейся ковариационной матрице (массив Numpy размером
2x2) искомое значение ковариации будет равно элементу в строке с индексом 0 и столбце с индексом
1.
"""

# Вычисляем ковариационную матрицу с помощью np.cov
cov_matrix = np.cov(a.T)

# Искомое значение ковариации будет равно элементу в строке с индексом 0 и столбце с индексом 1
cov_value = cov_matrix[0, 1]

print("Ковариационная матрица:\n", cov_matrix)
print("Искомое значение ковариации:", cov_value)

"""## Тема “Работа с данными в Pandas”

### Задание 1
Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со
столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и
['Тургенев', 'Чехов', 'Островский'].
<p/>Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно
содержатся данные:
<p/>[1, 1, 1, 2, 2, 3, 3],
<p/>['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и
поклонники']
<p/>[500, 400, 300, 350, 450, 600, 200]
"""

import pandas as pd

# Создаем датафрейм authors
authors = pd.DataFrame({
    'author_id': [1, 2, 3],
    'author_name': ['Тургенев', 'Чехов', 'Островский']
})

# Создаем датафрейм book
books = pd.DataFrame({
    'author_id': [1, 1, 1, 2, 2, 3, 3],
    'book_title': ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],
    'price': [500, 400, 300, 350, 450, 600, 200]
})

# Выводим датафреймы на экран
print("Authors DataFrame:")
print(authors)
print("\nBooks DataFrame:")
print(book)

"""### Задание 2
Получите датафрейм authors_price, соединив дата фреймы authors и books по полю author_id.
"""

# Объединяем датафреймы authors и books по полю author_id
authors_price = pd.merge(authors, books, on='author_id')

# Выводим результат на экран
print(authors_price)

"""## Задание 3
Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими
книгами.
"""

# Получаем датафрейм top5 с пятью самыми дорогими книгами
top5 = authors_price.nlargest(5, 'price')

# Выводим результат на экран
print(top5)

"""### Задание 4
Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat
должны быть четыре столбца:
author_name, min_price, max_price и mean_price,
в которых должны содержаться соответственно имя автора, минимальная, максимальная и средняя
цена на книги этого автора.
"""

# Создаем ноый дата фрейм путем группировки по имени автора и вычисляем минимальную, максимальную и среднюю цену
authors_stat = authors_price.groupby('author_name').agg(
    min_price=('price', 'min'),
    max_price=('price', 'max'),
    mean_price=('price', 'mean')
).reset_index()

# Выводим результат на экран
print(authors_stat)

"""### Задание 5**
Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться
данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка:
<p/>['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].
<p/>Просмотрите документацию по функции pd.pivot table с помощью вопросительного знака.
<p/>Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте
для этого функцию pd.pivot_table. При этом столбцы должны называться "твердая" и "мягкая", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy. Назовите полученный датасет book_info и сохраните его в формат pickle под названием
"book_info.pkl". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.
"""

# Добавляем новый столбец 'cover'
authors_price['cover'] = ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']

# Просматриваем документацию по функции pd.pivot_table
# ?pd.pivot_table

# Используем функцию pd.pivot_table для создания сводной таблицы
book_info = pd.pivot_table(authors_price,
                           values='price',
                           index='author_name',
                           columns='cover',
                           aggfunc='sum',
                           fill_value=0)

# Переименовываем столбцы
book_info.columns.name = None

# Сохраняем датафрейм book_info в формате pickle
book_info.to_pickle('book_info.pkl')

# Загружаем датафрейм из файла
book_info2 = pd.read_pickle('book_info.pkl')

# Проверяем идентичность датафреймов
print(book_info)
print(book_info2)
print(f'Датафреймы идентичны: {book_info.equals(book_info2)}')
